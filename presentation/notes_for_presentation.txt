Slide: Unbalanced Dataset
Train dataset - Target distribution
negative     7781
neutral     11118
positive     8582

Test dataset - Target distribution
sentiment
negative    1001
neutral     1430
positive    1103

Slide: Balanced Dataset, Smote

remove names, locations, company names

Slide: Text pre-processing Steps
1.  Remove null columns
2.  Delete textID column
3.  Remove punctuations / special characters
4.  Remove URLs
5.  Remove HTML tags
6.  Remove emoji
7.  Convert accented characters to ASCII characters
8.  Expand contractions
9.  Remove numbers (or converted on string)
10. Trim text and Remove extra whitespaces
11. Case Normalization: Lowercase all texts
12. Remove stop words, no need for this operations since in sentiment analysis we will lose information
    e.g.
    An example could be the following sentence: “I told you that she was not happy”.
    Let’s remove the stop words with the Aruana library:
    The result would be [‘told’, ‘happy’].
    https://medium.com/@limavallantin/why-is-removing-stop-words-not-always-a-good-idea-c8d35bd77214
13. Stemming vs Lemmatization (which one to choose?)
14. Tokenization (per sentence or all the corpus?)
15. Spell corrector


Polarity Sentiment Analysis

Sentiment analysis algorithms fall into one of three buckets
1. Rule-based
2. Automatic
3. Hybrid

For presentation
1. box plot with the target class distribution
2. compare text before-after cleaning



Text Vectorization - Convert natural language into numerical form
1. Bag of words
The problem with this method is that it doesn’t capture the meaning of the text, or the context in which words appear, even when using n-grams.
2. word2vec
3. Skip-Thought Vectors